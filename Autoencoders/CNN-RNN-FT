{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read CIFAR images\n",
    "\n",
    "import read_cifar10 as cf10\n",
    "\n",
    "#@read_data.restartable\n",
    "def cifar10_dataset_generator(dataset_name, batch_size, restrict_size=1000):\n",
    "    assert dataset_name in ['train', 'test']\n",
    "    assert batch_size > 0 or batch_size == -1  # -1 for entire dataset\n",
    "    \n",
    "    X_all_unrestricted, y_all = (cf10.load_training_data() if dataset_name == 'train'\n",
    "                                 else cf10.load_test_data())\n",
    "    \n",
    "    actual_restrict_size = restrict_size if dataset_name == 'train' else int(1e10)\n",
    "    X_all = X_all_unrestricted[:actual_restrict_size]\n",
    "    data_len = X_all.shape[0]\n",
    "    batch_size = batch_size if batch_size > 0 else data_len\n",
    "    \n",
    "    X_all_padded = np.concatenate([X_all, X_all[:batch_size]], axis=0)\n",
    "    y_all_padded = np.concatenate([y_all, y_all[:batch_size]], axis=0)\n",
    "    \n",
    "    for slice_i in range(math.ceil(data_len / batch_size)):\n",
    "        idx = slice_i * batch_size\n",
    "        #X_batch = X_all_padded[idx:idx + batch_size]\n",
    "        X_batch = X_all_padded[idx:idx + batch_size]*255  # bugfix: thanks Zezhou Sun!\n",
    "        y_batch = np.ravel(y_all_padded[idx:idx + batch_size])\n",
    "        yield X_batch.astype(np.uint8), y_batch.astype(np.uint8)\n",
    "\n",
    "cifar10_dataset_generators = {\n",
    "    'train': cifar10_dataset_generator('train', 1000),\n",
    "    'test': cifar10_dataset_generator('test', -1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load cifar-10 data\n",
    "cf10_tr=cf10.load_training_data()\n",
    "cf10_tr_img=cf10_tr[0]\n",
    "cf10_tr_label = cf10_tr[1]\n",
    "\n",
    "cf10_test=cf10.load_test_data()\n",
    "cf10_test_img=cf10_test[0]\n",
    "cf10_test_label = cf10_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import skimage.io\n",
    "def img2block(im):\n",
    "    '''\n",
    "    Image patching code. It patches a given RGB image into 32x32 blocks and returns a 4D array with size \n",
    "    [number_of_patches,32,32,3]\n",
    "    '''\n",
    "    im = im.astype(np.float32)\n",
    "    row,col,color = im.shape\n",
    "    im_bl=np.zeros((int(row*col/1024),32,32,3)).astype(np.float32)\n",
    "    count=0\n",
    "    for i in range(0,row-row%32,32):\n",
    "        for j in range(0,col-col%32,32):\n",
    "            im_bl[count,:,:,:]=im[i:i+32,j:j+32,:]\n",
    "            count = count +1\n",
    "    im_bl=im_bl/255.\n",
    "    return im_bl\n",
    "\n",
    "def block2img(img_blocks,img_size):\n",
    "    '''\n",
    "    Function for reconstructing the image back from patches\n",
    "    '''\n",
    "    row,col = img_size\n",
    "    img=np.zeros((row,col,3)).astype(np.float32)\n",
    "    n,k,l,c=img_blocks.shape\n",
    "                 \n",
    "    for i in range(0,int(row/k)):\n",
    "        for j in range(0,int(col/k)):\n",
    "            img[i*k:(i+1)*k,j*l:(j+1)*l,:]=img_blocks[int(i*col/k+j),:,:,:]\n",
    "    return img\n",
    "\n",
    "#Get the patches of lena image\n",
    "lena_img = skimage.io.imread('../test_img/lena512color.tiff')\n",
    "lena_32=img2block(lena_img)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for converting a double to uint8\n",
    "def convert2uint8(img):\n",
    "    img[img>255]=255\n",
    "    img[img<0]=0\n",
    "    return img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2 - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create the inputs in the desired format\n",
    "x_tr = cf10_tr_img.astype(np.float32)#*255.\n",
    "x_test = cf10_test_img.astype(np.float32)#*255.\n",
    "x_test=x_test[:200,:,:,:]\n",
    "img = skimage.io.imread('../test_img/lena512color.tiff')\n",
    "img_32=img2block(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_autoencoder(x_,kernels1=[5,7],kernels2=[7,5],filters1=[16,128],filters2=[128,3],pool_size=[1,2,2,1]):\n",
    "    '''\n",
    "    Autoencoder network\n",
    "    \n",
    "    Inputs:\n",
    "    x_ (tf.placeholder) : Input tensor\n",
    "    kernels1 (1D array) : Size of the encoder kernels (assumed square kernels)\n",
    "    kernels2 (1D array) : Size of the decoder kernels (assumed square kernels)\n",
    "    filters1 (1D array) : Number of filters in encoder layers\n",
    "    filters2 (1D array) : Number of filters in decoder layers\n",
    "    pool_size (1D array): Pooling size in each layer. Its length must be equal to len(kernels1)+len(kernels2)\n",
    "                          First len(kernels1) terms will be used as pooling layers of encoder/\n",
    "                          Remainin terms will be used as unpooling layers of decoder\n",
    "                          \n",
    "    Returns:\n",
    "    out_ (tf.placeholder)     : Output of the autoencoder without quantization in the middle\n",
    "    out_quant (tf.placeholder): Output of the autoencoder with quantization in the middle\n",
    "    '''\n",
    "    out_=x_\n",
    "    \n",
    "    #Encoder\n",
    "    for k in range(len(kernels1)):\n",
    "        conv = tf.layers.conv2d(inputs=out_,\n",
    "                                filters=filters1[k],\n",
    "                                kernel_size=[kernels1[k],kernels1[k]],\n",
    "                                padding=\"same\",\n",
    "                                activation=tf.nn.relu,\n",
    "                                name='conv'+str(k))\n",
    "        pool_now=pool_size[k]\n",
    "        if(pool_now==1):\n",
    "            out_=conv\n",
    "        else:\n",
    "            out_ = tf.layers.max_pooling2d(inputs=conv, \n",
    "                                           pool_size=[pool_now,pool_now], \n",
    "                                           strides=pool_now,\n",
    "                                           name = 'pool'+str(k))\n",
    "        \n",
    "        \n",
    "    #Quantization of output\n",
    "    out_quant=tf.round(out_*256.)/256.\n",
    "\n",
    "    #Decoder\n",
    "    for k in range(len(kernels2)):\n",
    "        with tf.variable_scope(\"deconv\") as var_scope:\n",
    "            pool_now=pool_size[k+len(kernels1)]\n",
    "            if(pool_now==1):\n",
    "                x_up=out_\n",
    "                out_ = tf.layers.conv2d(inputs=x_up,\n",
    "                                        filters=filters2[k],\n",
    "                                        kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                        padding=\"same\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        name='deconv'+str(k))\n",
    "                var_scope.reuse_variables() \n",
    "                x_quant_up=out_quant\n",
    "                out_quant = tf.layers.conv2d(inputs=x_quant_up,\n",
    "                                            filters=filters2[k],\n",
    "                                            kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                            padding=\"same\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            name='deconv'+str(k))\n",
    "            else:\n",
    "                #Bilinear interpolation of images\n",
    "                sh = out_.get_shape().as_list()\n",
    "                x_up=tf.image.resize_images(out_,[sh[1]*pool_now,sh[2]*pool_now])\n",
    "                #Convolution\n",
    "                out_ = tf.layers.conv2d(inputs=x_up,\n",
    "                                        filters=filters2[k],\n",
    "                                        kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                        padding=\"same\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        name='deconv'+str(k))\n",
    "                var_scope.reuse_variables() \n",
    "                x_quant_up=tf.image.resize_images(out_quant,[sh[1]*pool_now,sh[2]*pool_now])\n",
    "                out_quant = tf.layers.conv2d(inputs=x_quant_up,\n",
    "                                            filters=filters2[k],\n",
    "                                            kernel_size=[kernels2[k],kernels2[k]],\n",
    "                                            padding=\"same\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            name='deconv'+str(k))\n",
    "\n",
    "\n",
    "    return out_,out_quant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_classification_loss_mse(kernels1=[5,7],kernels2=[7,5],\n",
    "                                 filters1=[16,128],filters2=[128,3],\n",
    "                                pool_size=[1,2,2,1],learning_rate=1.,FT=False):\n",
    "    '''\n",
    "    MSE based autoencoder optimizer.\n",
    "    \n",
    "    Inputs:\n",
    "    kernels1 (1D array) : Size of the encoder kernels (assumed square kernels)\n",
    "    kernels2 (1D array) : Size of the decoder kernels (assumed square kernels)\n",
    "    filters1 (1D array) : Number of filters in encoder layers\n",
    "    filters2 (1D array) : Number of filters in decoder layers\n",
    "    pool_size (1D array): Pooling size in each layer. Its length must be equal to len(kernels1)+len(kernels2)\n",
    "                          First len(kernels1) terms will be used as pooling layers of encoder/\n",
    "                          Remainin terms will be used as unpooling layers of decoder\n",
    "    learning_rate(float): Learning rate of the optimizer\n",
    "    FT (boolean)        : Boolean value for fine-tuning operation on decoder weights\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    model_dict          : Dictionary of the required output files\n",
    "    '''\n",
    "    \n",
    "    with tf.Graph().as_default() as g:\n",
    "        with tf.device(\"/gpu:0\"):  # use gpu:0 if on GPU\n",
    "            x_ = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "            (x_out,x_out_quant)=cnn_autoencoder(x_,pool_size=pool_size,kernels1=kernels1,filters1=filters1,\n",
    "                                kernels2=kernels2,filters2=filters2)\n",
    "\n",
    "            mse_loss1=tf.reduce_mean(tf.subtract(x_,x_out)**2)\n",
    "            mse_loss2=tf.reduce_mean(tf.subtract(x_,x_out_quant)**2)\n",
    "            \n",
    "            trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            if(FT):\n",
    "                with tf.variable_scope('deconv', reuse=True) as vs:\n",
    "                    var_list=[v for v in tf.global_variables() if v.name.startswith(vs.name)]\n",
    "                train_op = trainer.minimize(mse_loss1,var_list=var_list)\n",
    "            else:\n",
    "                train_op = trainer.minimize(mse_loss1)\n",
    "\n",
    "    model_dict = {'graph': g, 'inputs': x_,'outputs':x_out, 'train_op': train_op, 'loss1': mse_loss1,'loss2': mse_loss2}\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model_dict,x_32=img_32, train_every=100, test_every=200, load=False,\n",
    "                learning_rate=1.,fname='cifar10_recon',outname='/tmp/cnn_autoencoder',ftname='/tmp/cnn_autoencoder'):\n",
    "    '''\n",
    "    Inputs:\n",
    "    model_dict: Output of apply_classification_loss_mse\n",
    "    x_tr      : Training images\n",
    "    x_test    : Test Images\n",
    "    x_32      : 32x32 patches of a big image\n",
    "    load      : Boolean for loading the weights from pre-trained network\n",
    "    fname     : Directory to save outputs\n",
    "    outname   : Directory to save (load=False) or load (load=True) weights\n",
    "    ftname    : Directory to save new weights when load+True\n",
    "    '''\n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver=tf.train.Saver()\n",
    "        if(load):\n",
    "            saver.restore(sess, outname)\n",
    "            print(\"Model loaded\")\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        ids=[i for i in range(100)]\n",
    "        for iter_i in range(20001):\n",
    "            batch_xs = x_tr[ids,:,:,:] \n",
    "            ids=[(ids[0]+100+i)%x_tr.shape[0] for i in range(100)]\n",
    "            sess.run(model_dict['train_op'], feed_dict={model_dict['inputs']: batch_xs})\n",
    "            \n",
    "            # test trained model\n",
    "            if iter_i % train_every == 0:\n",
    "                tf_feed_dict = {model_dict['inputs']: batch_xs}\n",
    "                loss_val = sess.run(model_dict['loss1'], feed_dict={model_dict['inputs']: batch_xs})\n",
    "                print('iteration %d\\t train mse: %.3E\\t'%(iter_i,loss_val))\n",
    "                if iter_i % test_every == 0:\n",
    "                    #tf_feed_dict = {x_: x_test}\n",
    "                    loss_val1 = sess.run(model_dict['loss1'], feed_dict={model_dict['inputs']: x_test})\n",
    "                    loss_val2 = sess.run(model_dict['loss2'], feed_dict={model_dict['inputs']: x_test})\n",
    "                    print('iteration %d\\t TEST MSE: %.3E\\t TEST MSE(Quantized): %.3E\\t'%(iter_i,loss_val1,loss_val2))\n",
    "                    \n",
    "                    img_block=sess.run(model_dict['outputs'], \n",
    "                                       feed_dict={model_dict['inputs']:img_32})\n",
    "                    x_from_test=sess.run(model_dict['outputs'], \n",
    "                                         feed_dict={model_dict['inputs']:x_test[:5,:,:,:].reshape([-1,32,32,3])})\n",
    "                    \n",
    "                    img_recon=block2img(img_block,(512,512))\n",
    "                    img_recon = convert2uint8(img_recon*255.)\n",
    "                    skimage.io.imsave('../'+fname+'/img32_recon_'+str(int(iter_i/test_every))+'.tiff',img_recon)\n",
    "\n",
    "                    for i in range(5):\n",
    "                        img_recon=convert2uint8((255*x_from_test[i,:,:,:]).reshape([32,32,3])).astype(np.uint8)\n",
    "                        skimage.io.imsave('../'+fname+'/test'+str(i)+'_'+str(int(iter_i/test_every))+'.tiff',img_recon)\n",
    "                        \n",
    "        saver = tf.train.Saver()\n",
    "        if(load):\n",
    "            outname=ftname\n",
    "        save_path = saver.save(sess, outname)\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-AE with the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#YOU NEED TO CREATE A FOLDER NAMED 'cifar10_recon0' BEFORE RUNNING THAT CODE\n",
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse(kernels1=[5,7,9,9],kernels2=[9,7,7,5],\n",
    "                                     filters1=[128,64,16,4],filters2=[8,8,3,3],\n",
    "                                     pool_size=[1,2,2,1,1,2,2,1],learning_rate=7e-5)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=2000,load=False,\n",
    "                    fname='cifar10_recon0',outname='/tmp/cnnx4_test0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-AE-FT with the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOU NEED TO CREATE A FOLDER NAMED 'cifar10_recon1' BEFORE RUNNING THAT CODE\n",
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse(kernels1=[5,7,9,9],kernels2=[9,7,7,5],\n",
    "                                     filters1=[128,64,16,4],filters2=[8,8,3,3],\n",
    "                                     pool_size=[1,2,2,1,1,2,2,1],learning_rate=7e-5)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=2000,load=False,\n",
    "                    fname='cifar10_recon1',outname='/tmp/cnnx4_test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code for fine-tuning\n",
    "#YOU NEED TO CREATE A FOLDER NAMED 'cifar10_recon2' BEFORE RUNNING THAT CODE\n",
    "img = skimage.io.imread('../test_img/lena512color.tiff')\n",
    "img_32=img2block(img)\n",
    "x_tr=img_32.copy()\n",
    "\n",
    "tmp=x_tr.copy()\n",
    "x_tr=img_32.copy()\n",
    "idx=np.random.permutation(x_tr.shape[0])\n",
    "x_tr=x_tr[idx,:,:,:]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model_dict=apply_classification_loss_mse(kernels1=[5,7,9],kernels2=[9,7,5],\n",
    "                                     filters1=[64,16,3],filters2=[3,3,3],\n",
    "                                     pool_size=[1,2,2,2,2,1],learning_rate=1e-6,FT=True)\n",
    "saver = train_model(model_dict, [], train_every=100, test_every=1000,load=True,\n",
    "                    fname='cifar10_recon2',outname='/tmp/cnnx4_test1',ftname='/tmp/cnnx4_test1_lion')\n",
    "\n",
    "x_tr=tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Apply the pre-trained netowrk on another image\n",
    "\n",
    "tfsave ='/tmp/cnnx4_test0'\n",
    "imgpath = '../test_img/lion.tiff'\n",
    "outpath='../test_img/lion_recon2_convrealFTpx8.tiff'\n",
    "with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "#with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tfsave)\n",
    "    print(\"Model loaded\")\n",
    "    \n",
    "    img = skimage.io.imread(imgpath)\n",
    "    [w,l,c]=img.shape\n",
    "    img_32=img2block(img)\n",
    "    img_block = np.zeros(img_32.shape)\n",
    "    \n",
    "    n= np.floor(img_32.shape[0]/2000).astype(int)\n",
    "    print(n)\n",
    "    for i in range(0,n):\n",
    "        print(str(i+1)+'th slice')\n",
    "        img_block[i*2000:(i+1)*2000,:,:,:]=sess.run(model_dict['outputs'], \n",
    "                                    feed_dict={model_dict['inputs']:img_32[i*2000:(i+1)*2000,:,:,:]})\n",
    "    img_block[n*2000:,:,:,:]=sess.run(model_dict['outputs'], \n",
    "                                    feed_dict={model_dict['inputs']:img_32[n*2000:,:,:,:]})\n",
    "        \n",
    "    img_recon=block2img(img_block,(w,l))\n",
    "    img_recon = convert2uint8(img_recon*255.)\n",
    "    skimage.io.imsave(outpath,img_recon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
